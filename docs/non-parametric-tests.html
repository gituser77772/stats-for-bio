<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 30 Non-parametric tests | Data Analysis and Statistics with R</title>
  <meta name="description" content="A Course book for Data Analysis and Statistics with R extended from the Department of Animal and Plant Sciences, University of Sheffield. Credit: Dylan Z. Childs" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 30 Non-parametric tests | Data Analysis and Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A Course book for Data Analysis and Statistics with R extended from the Department of Animal and Plant Sciences, University of Sheffield. Credit: Dylan Z. Childs" />
  <meta name="github-repo" content="davan690/stats-for-bio" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 30 Non-parametric tests | Data Analysis and Statistics with R" />
  
  <meta name="twitter:description" content="A Course book for Data Analysis and Statistics with R extended from the Department of Animal and Plant Sciences, University of Sheffield. Credit: Dylan Z. Childs" />
  

<meta name="author" content="Anthony Davidson; Dylan Z. Childs; others" />


<meta name="date" content="2020-07-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="contingency-tables.html"/>
<link rel="next" href="choosing-models-and-tests.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<style type="text/css">

.warning-box {
  border: 3px solid #e60000;
  margin:  25px;
  padding: 10px 10px 5px 10px;
  border-radius: 6px 6px 6px 6px;
}

.advanced-box {
  border: 3px solid #268bd2;
  margin:  25px;
  padding: 10px 10px 5px 10px;
  border-radius: 6px 6px 6px 6px;
}

.do-something {
  border: 3px solid #803e00;
  margin:  25px;
  padding: 10px 10px 5px 10px;
  border-radius: 6px 6px 6px 6px;
}

</style>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Basic bio-statistics teaching resources</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Resource information and overview</a><ul>
<li class="chapter" data-level="1.0.1" data-path="index.html"><a href="index.html#view-book"><i class="fa fa-check"></i><b>1.0.1</b> View Book</a></li>
</ul></li>
<li class="part"><span><b>I Collecting and Using Data</b></span></li>
<li class="chapter" data-level="2" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html"><i class="fa fa-check"></i><b>2</b> Programming prerequisites</a><ul>
<li class="chapter" data-level="2.0.1" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#files-and-folders"><i class="fa fa-check"></i><b>2.0.1</b> Files and folders</a></li>
<li class="chapter" data-level="2.1" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#statistics"><i class="fa fa-check"></i><b>2.1</b> Statistics</a><ul>
<li class="chapter" data-level="2.1.1" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#r"><i class="fa fa-check"></i><b>2.1.1</b> R</a></li>
<li class="chapter" data-level="2.1.2" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#rstudio"><i class="fa fa-check"></i><b>2.1.2</b> RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#starting-an-r-session-in-rstudio"><i class="fa fa-check"></i><b>2.2</b> Starting an R session in RStudio</a></li>
<li class="chapter" data-level="2.3" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#using-packages"><i class="fa fa-check"></i><b>2.3</b> Using packages</a><ul>
<li class="chapter" data-level="2.3.1" data-path="programming-prerequisites.html"><a href="programming-prerequisites.html#text-editors"><i class="fa fa-check"></i><b>2.3.1</b> Text editors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-scientific-process.html"><a href="the-scientific-process.html"><i class="fa fa-check"></i><b>3</b> The scientific process</a><ul>
<li class="chapter" data-level="3.1" data-path="the-scientific-process.html"><a href="the-scientific-process.html#stages-scientific-process"><i class="fa fa-check"></i><b>3.1</b> Stages in the scientific process</a><ul>
<li class="chapter" data-level="3.1.1" data-path="the-scientific-process.html"><a href="the-scientific-process.html#stages-observations"><i class="fa fa-check"></i><b>3.1.1</b> Observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-scientific-process.html"><a href="the-scientific-process.html#stages-questions"><i class="fa fa-check"></i><b>3.1.2</b> Questions</a></li>
<li class="chapter" data-level="3.1.3" data-path="the-scientific-process.html"><a href="the-scientific-process.html#stages-hypotheses"><i class="fa fa-check"></i><b>3.1.3</b> Hypotheses</a></li>
<li class="chapter" data-level="3.1.4" data-path="the-scientific-process.html"><a href="the-scientific-process.html#stages-predictions"><i class="fa fa-check"></i><b>3.1.4</b> Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-scientific-process.html"><a href="the-scientific-process.html#hypothesis-testing"><i class="fa fa-check"></i><b>3.2</b> Hypothesis testing</a></li>
<li class="chapter" data-level="3.3" data-path="the-scientific-process.html"><a href="the-scientific-process.html#are-we-sure"><i class="fa fa-check"></i><b>3.3</b> Don’t we ever know anything for sure?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-and-variables.html"><a href="data-and-variables.html"><i class="fa fa-check"></i><b>4</b> Data and variables</a><ul>
<li class="chapter" data-level="4.1" data-path="data-and-variables.html"><a href="data-and-variables.html#observations-on-material-and-obvious-things"><i class="fa fa-check"></i><b>4.1</b> “Observations on material and obvious things”</a></li>
<li class="chapter" data-level="4.2" data-path="data-and-variables.html"><a href="data-and-variables.html#reading-data-into-r"><i class="fa fa-check"></i><b>4.2</b> Reading data into R</a></li>
<li class="chapter" data-level="4.3" data-path="data-and-variables.html"><a href="data-and-variables.html#var-types"><i class="fa fa-check"></i><b>4.3</b> Types of variable</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-and-variables.html"><a href="data-and-variables.html#nominal-categorical-variables"><i class="fa fa-check"></i><b>4.3.1</b> Nominal (categorical) variables</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-and-variables.html"><a href="data-and-variables.html#ordinal-categorical-data"><i class="fa fa-check"></i><b>4.3.2</b> Ordinal (categorical) data</a></li>
<li class="chapter" data-level="4.3.3" data-path="data-and-variables.html"><a href="data-and-variables.html#interval-scale-numeric-variables"><i class="fa fa-check"></i><b>4.3.3</b> Interval scale (numeric) variables</a></li>
<li class="chapter" data-level="4.3.4" data-path="data-and-variables.html"><a href="data-and-variables.html#ratio-scale-numeric-variables"><i class="fa fa-check"></i><b>4.3.4</b> Ratio scale (numeric) variables</a></li>
<li class="chapter" data-level="4.3.5" data-path="data-and-variables.html"><a href="data-and-variables.html#why-does-the-distinction-matter"><i class="fa fa-check"></i><b>4.3.5</b> Why does the distinction matter?</a></li>
<li class="chapter" data-level="4.3.6" data-path="data-and-variables.html"><a href="data-and-variables.html#which-is-best"><i class="fa fa-check"></i><b>4.3.6</b> Which is best?</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-and-variables.html"><a href="data-and-variables.html#accuracy-precision"><i class="fa fa-check"></i><b>4.4</b> Accuracy and precision</a><ul>
<li class="chapter" data-level="4.4.1" data-path="data-and-variables.html"><a href="data-and-variables.html#what-do-they-mean"><i class="fa fa-check"></i><b>4.4.1</b> What do they mean?</a></li>
<li class="chapter" data-level="4.4.2" data-path="data-and-variables.html"><a href="data-and-variables.html#implied-precision-significant-figures"><i class="fa fa-check"></i><b>4.4.2</b> Implied precision – significant figures</a></li>
<li class="chapter" data-level="4.4.3" data-path="data-and-variables.html"><a href="data-and-variables.html#how-precise-should-measurements-be"><i class="fa fa-check"></i><b>4.4.3</b> How precise should measurements be?</a></li>
<li class="chapter" data-level="4.4.4" data-path="data-and-variables.html"><a href="data-and-variables.html#error-bias-and-prejudice"><i class="fa fa-check"></i><b>4.4.4</b> Error, bias and prejudice</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="learning-from-data.html"><a href="learning-from-data.html"><i class="fa fa-check"></i><b>5</b> Learning from data</a><ul>
<li class="chapter" data-level="5.1" data-path="learning-from-data.html"><a href="learning-from-data.html#populations"><i class="fa fa-check"></i><b>5.1</b> Populations</a></li>
<li class="chapter" data-level="5.2" data-path="learning-from-data.html"><a href="learning-from-data.html#learning-about-populations"><i class="fa fa-check"></i><b>5.2</b> Learning about populations</a></li>
<li class="chapter" data-level="5.3" data-path="learning-from-data.html"><a href="learning-from-data.html#morph-example"><i class="fa fa-check"></i><b>5.3</b> A simple example</a></li>
<li class="chapter" data-level="5.4" data-path="learning-from-data.html"><a href="learning-from-data.html#now-what"><i class="fa fa-check"></i><b>5.4</b> Now what?</a></li>
</ul></li>
<li class="part"><span><b>II Statistical Concepts</b></span></li>
<li class="chapter" data-level="6" data-path="sampling-error.html"><a href="sampling-error.html"><i class="fa fa-check"></i><b>6</b> Sampling error</a><ul>
<li class="chapter" data-level="6.1" data-path="sampling-error.html"><a href="sampling-error.html#sampling-error-1"><i class="fa fa-check"></i><b>6.1</b> Sampling error</a></li>
<li class="chapter" data-level="6.2" data-path="sampling-error.html"><a href="sampling-error.html#sampling-distributions"><i class="fa fa-check"></i><b>6.2</b> Sampling distributions</a></li>
<li class="chapter" data-level="6.3" data-path="sampling-error.html"><a href="sampling-error.html#the-effect-of-sample-size"><i class="fa fa-check"></i><b>6.3</b> The effect of sample size</a></li>
<li class="chapter" data-level="6.4" data-path="sampling-error.html"><a href="sampling-error.html#the-standard-error"><i class="fa fa-check"></i><b>6.4</b> The standard error</a></li>
<li class="chapter" data-level="6.5" data-path="sampling-error.html"><a href="sampling-error.html#what-is-the-point-of-all-this"><i class="fa fa-check"></i><b>6.5</b> What is the point of all this?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html"><i class="fa fa-check"></i><b>7</b> Statistical significance and <em>p</em>-values</a><ul>
<li class="chapter" data-level="7.1" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#bootstrap"><i class="fa fa-check"></i><b>7.1</b> Estimating a sampling distribution</a><ul>
<li class="chapter" data-level="7.1.1" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#bootstrap-overview"><i class="fa fa-check"></i><b>7.1.1</b> Overview of bootstrapping</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#doing-it-for-real"><i class="fa fa-check"></i><b>7.1.2</b> Doing it for real</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#statistical-significance"><i class="fa fa-check"></i><b>7.2</b> Statistical significance</a></li>
<li class="chapter" data-level="7.3" data-path="statistical-significance-and-p-values.html"><a href="statistical-significance-and-p-values.html#concluding-remarks"><i class="fa fa-check"></i><b>7.3</b> Concluding remarks</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="comparing-populations.html"><a href="comparing-populations.html"><i class="fa fa-check"></i><b>8</b> Comparing populations</a><ul>
<li class="chapter" data-level="8.1" data-path="comparing-populations.html"><a href="comparing-populations.html#making-comparisons"><i class="fa fa-check"></i><b>8.1</b> Making comparisons</a></li>
<li class="chapter" data-level="8.2" data-path="comparing-populations.html"><a href="comparing-populations.html#morph-weights-eg"><i class="fa fa-check"></i><b>8.2</b> A new example</a></li>
<li class="chapter" data-level="8.3" data-path="comparing-populations.html"><a href="comparing-populations.html#evaluating-differences-between-population-means"><i class="fa fa-check"></i><b>8.3</b> Evaluating differences between population means</a></li>
<li class="chapter" data-level="8.4" data-path="comparing-populations.html"><a href="comparing-populations.html#a-permutation-test"><i class="fa fa-check"></i><b>8.4</b> A permutation test</a></li>
<li class="chapter" data-level="8.5" data-path="comparing-populations.html"><a href="comparing-populations.html#what-have-we-learned"><i class="fa fa-check"></i><b>8.5</b> What have we learned?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html"><i class="fa fa-check"></i><b>9</b> Hypotheses and <em>p</em>-values</a><ul>
<li class="chapter" data-level="9.1" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#a-few-words-about-the-null-hypothesis"><i class="fa fa-check"></i><b>9.1</b> A few words about the null hypothesis</a><ul>
<li class="chapter" data-level="9.1.1" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#hypotheses-and-null-hypotheses"><i class="fa fa-check"></i><b>9.1.1</b> Hypotheses and null hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#interpreting-and-reporting-p-values"><i class="fa fa-check"></i><b>9.2</b> Interpreting and reporting <em>p</em>-values</a><ul>
<li class="chapter" data-level="9.2.1" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#careful-with-those-p-values"><i class="fa fa-check"></i><b>9.2.1</b> Careful with those <em>p</em>-values</a></li>
<li class="chapter" data-level="9.2.2" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#presenting-p-values"><i class="fa fa-check"></i><b>9.2.2</b> Presenting <em>p</em>-values</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="hypotheses-and-p-values.html"><a href="hypotheses-and-p-values.html#biological-vs.-statistical-significance"><i class="fa fa-check"></i><b>9.3</b> Biological vs. statistical significance</a></li>
</ul></li>
<li class="part"><span><b>III Simple Statistics</b></span></li>
<li class="chapter" data-level="10" data-path="parametric-statistics.html"><a href="parametric-statistics.html"><i class="fa fa-check"></i><b>10</b> Parametric statistics</a><ul>
<li class="chapter" data-level="10.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="parametric-statistics.html"><a href="parametric-statistics.html#math-models"><i class="fa fa-check"></i><b>10.2</b> Mathematical models</a></li>
<li class="chapter" data-level="10.3" data-path="parametric-statistics.html"><a href="parametric-statistics.html#parametric-stats"><i class="fa fa-check"></i><b>10.3</b> The normal distribution</a><ul>
<li class="chapter" data-level="10.3.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>10.3.1</b> Standard error of the mean</a></li>
<li class="chapter" data-level="10.3.2" data-path="parametric-statistics.html"><a href="parametric-statistics.html#the-t-distribution"><i class="fa fa-check"></i><b>10.3.2</b> The <em>t</em> distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>11</b> Correlation</a><ul>
<li class="chapter" data-level="11.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="correlation.html"><a href="correlation.html#pearsons-product-moment-correlation-coefficient"><i class="fa fa-check"></i><b>11.2</b> Pearson’s product-moment correlation coefficient</a><ul>
<li class="chapter" data-level="11.2.1" data-path="correlation.html"><a href="correlation.html#pearsons-product-moment-correlation-coefficient-in-r"><i class="fa fa-check"></i><b>11.2.1</b> Pearson’s product-moment correlation coefficient in R</a></li>
<li class="chapter" data-level="11.2.2" data-path="correlation.html"><a href="correlation.html#reporting-the-result"><i class="fa fa-check"></i><b>11.2.2</b> Reporting the result</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Regression and ANOVA</b></span></li>
<li class="chapter" data-level="12" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html"><i class="fa fa-check"></i><b>12</b> Relationships and regression</a><ul>
<li class="chapter" data-level="12.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#correlation-or-regression"><i class="fa fa-check"></i><b>12.2</b> Correlation or regression?</a></li>
<li class="chapter" data-level="12.3" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#what-does-linear-regression-do"><i class="fa fa-check"></i><b>12.3</b> What does linear regression do?</a></li>
<li class="chapter" data-level="12.4" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#how-does-simple-linear-regression-work"><i class="fa fa-check"></i><b>12.4</b> How does simple linear regression work?</a><ul>
<li class="chapter" data-level="12.4.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#finding-the-best-fit-line"><i class="fa fa-check"></i><b>12.4.1</b> Finding the best fit line</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#what-do-you-get-out-of-a-regression"><i class="fa fa-check"></i><b>12.5</b> What do you get out of a regression?</a><ul>
<li class="chapter" data-level="12.5.1" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#interpreting-a-regression"><i class="fa fa-check"></i><b>12.5.1</b> Interpreting a regression</a></li>
<li class="chapter" data-level="12.5.2" data-path="relationships-and-regression.html"><a href="relationships-and-regression.html#evaluating-hypotheses-inference"><i class="fa fa-check"></i><b>12.5.2</b> Evaluating hypotheses (‘inference’)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html"><i class="fa fa-check"></i><b>13</b> Simple regression in R</a><ul>
<li class="chapter" data-level="13.1" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#regression-in-R"><i class="fa fa-check"></i><b>13.1</b> Carrying out a simple linear regression in R</a></li>
<li class="chapter" data-level="13.2" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#first-steps"><i class="fa fa-check"></i><b>13.2</b> First steps</a><ul>
<li class="chapter" data-level="13.2.1" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#visualising-the-data"><i class="fa fa-check"></i><b>13.2.1</b> Visualising the data</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#model-fitting-and-significance-tests"><i class="fa fa-check"></i><b>13.3</b> Model fitting and significance tests</a><ul>
<li class="chapter" data-level="13.3.1" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#extracting-a-little-more-information"><i class="fa fa-check"></i><b>13.3.1</b> Extracting a little more information</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#present-results"><i class="fa fa-check"></i><b>13.4</b> Presenting results</a><ul>
<li class="chapter" data-level="13.4.1" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#plotting-the-fitted-line-and-the-data"><i class="fa fa-check"></i><b>13.4.1</b> Plotting the fitted line and the data</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#causation"><i class="fa fa-check"></i><b>13.5</b> What about causation?</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html"><i class="fa fa-check"></i><b>14</b> Introduction to one-way ANOVA</a><ul>
<li class="chapter" data-level="14.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#intro"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#why-do-we-need-anova-models"><i class="fa fa-check"></i><b>14.2</b> Why do we need ANOVA models?</a></li>
<li class="chapter" data-level="14.3" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#how-does-anova-work"><i class="fa fa-check"></i><b>14.3</b> How does ANOVA work?</a><ul>
<li class="chapter" data-level="14.3.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#degrees-of-freedom"><i class="fa fa-check"></i><b>14.3.1</b> Degrees of freedom</a></li>
<li class="chapter" data-level="14.3.2" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#mean-squares-variance-ratios-and-f-tests"><i class="fa fa-check"></i><b>14.3.2</b> Mean squares, variance ratios, and F-tests</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#different-kinds-of-anova-model"><i class="fa fa-check"></i><b>14.4</b> Different kinds of ANOVA model</a></li>
<li class="chapter" data-level="14.5" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#questions"><i class="fa fa-check"></i><b>14.5</b> Some common questions about ANOVA</a><ul>
<li class="chapter" data-level="14.5.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#can-anova-only-be-applied-to-experimental-data"><i class="fa fa-check"></i><b>14.5.1</b> Can ANOVA only be applied to experimental data?</a></li>
<li class="chapter" data-level="14.5.2" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#do-we-need-equal-replication"><i class="fa fa-check"></i><b>14.5.2</b> Do we need equal replication?</a></li>
<li class="chapter" data-level="14.5.3" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#can-anova-be-done-with-only-two-treatments"><i class="fa fa-check"></i><b>14.5.3</b> Can ANOVA be done with only two treatments?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html"><i class="fa fa-check"></i><b>15</b> One-way ANOVA in R</a><ul>
<li class="chapter" data-level="15.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#factors-in-r"><i class="fa fa-check"></i><b>15.2</b> Factors in R</a></li>
<li class="chapter" data-level="15.3" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#visualising-the-data"><i class="fa fa-check"></i><b>15.3</b> Visualising the data</a></li>
<li class="chapter" data-level="15.4" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#fitting-the-anova-model"><i class="fa fa-check"></i><b>15.4</b> Fitting the ANOVA model</a></li>
<li class="chapter" data-level="15.5" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#interpreting-the-results"><i class="fa fa-check"></i><b>15.5</b> Interpreting the results</a></li>
<li class="chapter" data-level="15.6" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#summarise-results"><i class="fa fa-check"></i><b>15.6</b> Summarising and presenting the results of ANOVA</a></li>
</ul></li>
<li class="part"><span><b>V Doing More with Models</b></span></li>
<li class="chapter" data-level="16" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html"><i class="fa fa-check"></i><b>16</b> Assumptions and diagnostics</a><ul>
<li class="chapter" data-level="16.1" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#understanding-data"><i class="fa fa-check"></i><b>16.1</b> Understanding data</a></li>
<li class="chapter" data-level="16.2" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#assumptions-of-regression"><i class="fa fa-check"></i><b>16.2</b> Assumptions of regression</a></li>
<li class="chapter" data-level="16.3" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#regres-diagnose"><i class="fa fa-check"></i><b>16.3</b> Regression diagnostics</a><ul>
<li class="chapter" data-level="16.3.1" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#fitted-values"><i class="fa fa-check"></i><b>16.3.1</b> Fitted values</a></li>
<li class="chapter" data-level="16.3.2" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#checking-the-linearity-assumption"><i class="fa fa-check"></i><b>16.3.2</b> Checking the linearity assumption</a></li>
<li class="chapter" data-level="16.3.3" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#checking-the-normality-assumption"><i class="fa fa-check"></i><b>16.3.3</b> Checking the normality assumption</a></li>
<li class="chapter" data-level="16.3.4" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#checking-the-constant-variance-assumption"><i class="fa fa-check"></i><b>16.3.4</b> Checking the constant variance assumption</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="assumptions-and-diagnostics.html"><a href="assumptions-and-diagnostics.html#assumptions-of-one-way-anova"><i class="fa fa-check"></i><b>16.4</b> Assumptions of one-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="using-regression-diagnostics.html"><a href="using-regression-diagnostics.html"><i class="fa fa-check"></i><b>17</b> Using regression diagnostics</a><ul>
<li class="chapter" data-level="17.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="using-regression-diagnostics.html"><a href="using-regression-diagnostics.html#diagnostics-for-regression"><i class="fa fa-check"></i><b>17.2</b> Diagnostics for regression</a></li>
<li class="chapter" data-level="17.3" data-path="using-regression-diagnostics.html"><a href="using-regression-diagnostics.html#diagnostics-for-one-way-anova"><i class="fa fa-check"></i><b>17.3</b> Diagnostics for one-way ANOVA</a><ul>
<li class="chapter" data-level="17.3.1" data-path="using-regression-diagnostics.html"><a href="using-regression-diagnostics.html#aside-formal-test-of-equality-of-variance"><i class="fa fa-check"></i><b>17.3.1</b> Aside: formal test of equality of variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="data-transformations.html"><a href="data-transformations.html"><i class="fa fa-check"></i><b>18</b> Data transformations</a><ul>
<li class="chapter" data-level="18.1" data-path="data-transformations.html"><a href="data-transformations.html#transforms-introduction"><i class="fa fa-check"></i><b>18.1</b> Data that violate ANOVA assumptions</a></li>
<li class="chapter" data-level="18.2" data-path="data-transformations.html"><a href="data-transformations.html#ant-eg"><i class="fa fa-check"></i><b>18.2</b> Data transformation: ANOVAs and <em>t</em>-tests</a><ul>
<li class="chapter" data-level="18.2.1" data-path="data-transformations.html"><a href="data-transformations.html#the-data-foraging-in-ants"><i class="fa fa-check"></i><b>18.2.1</b> The data: foraging in ants</a></li>
<li class="chapter" data-level="18.2.2" data-path="data-transformations.html"><a href="data-transformations.html#fit-the-model-and-checking-the-assumptions"><i class="fa fa-check"></i><b>18.2.2</b> Fit the model and checking the assumptions</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="data-transformations.html"><a href="data-transformations.html#carry-on"><i class="fa fa-check"></i><b>18.3</b> Carrying on anyway</a></li>
<li class="chapter" data-level="18.4" data-path="data-transformations.html"><a href="data-transformations.html#transform"><i class="fa fa-check"></i><b>18.4</b> Transforming the data</a><ul>
<li class="chapter" data-level="18.4.1" data-path="data-transformations.html"><a href="data-transformations.html#the-logarithmic-transformation"><i class="fa fa-check"></i><b>18.4.1</b> The logarithmic transformation</a></li>
<li class="chapter" data-level="18.4.2" data-path="data-transformations.html"><a href="data-transformations.html#presenting-results-from-analyses-of-transformed-data"><i class="fa fa-check"></i><b>18.4.2</b> Presenting results from analyses of transformed data</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="data-transformations.html"><a href="data-transformations.html#trans-types"><i class="fa fa-check"></i><b>18.5</b> Types of transformations</a><ul>
<li class="chapter" data-level="18.5.1" data-path="data-transformations.html"><a href="data-transformations.html#logarithms"><i class="fa fa-check"></i><b>18.5.1</b> Logarithms</a></li>
<li class="chapter" data-level="18.5.2" data-path="data-transformations.html"><a href="data-transformations.html#square-roots"><i class="fa fa-check"></i><b>18.5.2</b> Square roots</a></li>
<li class="chapter" data-level="18.5.3" data-path="data-transformations.html"><a href="data-transformations.html#arcsine-square-root"><i class="fa fa-check"></i><b>18.5.3</b> Arcsine square root</a></li>
<li class="chapter" data-level="18.5.4" data-path="data-transformations.html"><a href="data-transformations.html#squaring"><i class="fa fa-check"></i><b>18.5.4</b> Squaring</a></li>
<li class="chapter" data-level="18.5.5" data-path="data-transformations.html"><a href="data-transformations.html#situations-which-cannot-be-dealt-with-by-transformations"><i class="fa fa-check"></i><b>18.5.5</b> Situations which cannot be dealt with by transformations</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="data-transformations.html"><a href="data-transformations.html#what-about-other-kinds-of-models"><i class="fa fa-check"></i><b>18.6</b> What about other kinds of models?</a></li>
<li class="chapter" data-level="18.7" data-path="data-transformations.html"><a href="data-transformations.html#final-thoughts"><i class="fa fa-check"></i><b>18.7</b> Final thoughts</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html"><i class="fa fa-check"></i><b>19</b> Multiple comparison tests</a><ul>
<li class="chapter" data-level="19.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#mult-comp-R"><i class="fa fa-check"></i><b>19.2</b> Tukey’s HSD in R</a></li>
<li class="chapter" data-level="19.3" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#how-to-summarise-multiple-comparison-results"><i class="fa fa-check"></i><b>19.3</b> How to summarise multiple-comparison results</a></li>
<li class="chapter" data-level="19.4" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#doing-it-the-easy-way"><i class="fa fa-check"></i><b>19.4</b> Doing it the easy way…</a></li>
<li class="chapter" data-level="19.5" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#summarise"><i class="fa fa-check"></i><b>19.5</b> Summarising and presenting the results of a Tukey test</a></li>
<li class="chapter" data-level="19.6" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#significant-anova-but-no-differences-in-a-tukey-test"><i class="fa fa-check"></i><b>19.6</b> Significant ANOVA but no differences in a Tukey test?</a></li>
</ul></li>
<li class="part"><span><b>VI Experimental Design</b></span></li>
<li class="chapter" data-level="20" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html"><i class="fa fa-check"></i><b>20</b> Principles of experimental design</a><ul>
<li class="chapter" data-level="20.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#jargon-busting"><i class="fa fa-check"></i><b>20.2</b> Jargon busting</a></li>
<li class="chapter" data-level="20.3" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#replication"><i class="fa fa-check"></i><b>20.3</b> Replication</a><ul>
<li class="chapter" data-level="20.3.1" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#independence"><i class="fa fa-check"></i><b>20.3.1</b> Independence and pseudoreplication</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#controls"><i class="fa fa-check"></i><b>20.4</b> Controls</a></li>
<li class="chapter" data-level="20.5" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#confounded-and-noisy-experiments"><i class="fa fa-check"></i><b>20.5</b> Confounded and noisy experiments</a><ul>
<li class="chapter" data-level="20.5.1" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#confounding"><i class="fa fa-check"></i><b>20.5.1</b> Confounding</a></li>
<li class="chapter" data-level="20.5.2" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#noise"><i class="fa fa-check"></i><b>20.5.2</b> Noise</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#dealing-with-confounding-effects-and-noise"><i class="fa fa-check"></i><b>20.6</b> Dealing with confounding effects and noise</a><ul>
<li class="chapter" data-level="20.6.1" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#randomisation"><i class="fa fa-check"></i><b>20.6.1</b> Randomisation</a></li>
<li class="chapter" data-level="20.6.2" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#blocking"><i class="fa fa-check"></i><b>20.6.2</b> Blocking</a></li>
<li class="chapter" data-level="20.6.3" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#experimental-control"><i class="fa fa-check"></i><b>20.6.3</b> Experimental control</a></li>
<li class="chapter" data-level="20.6.4" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#additional-treatments-designing-in-unwanted-variation"><i class="fa fa-check"></i><b>20.6.4</b> Additional treatments: ‘designing in’ unwanted variation</a></li>
</ul></li>
<li class="chapter" data-level="20.7" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#ethics-and-practicality"><i class="fa fa-check"></i><b>20.7</b> Ethics and practicality</a></li>
<li class="chapter" data-level="20.8" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#further-reading"><i class="fa fa-check"></i><b>20.8</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html"><i class="fa fa-check"></i><b>21</b> Paired-sample t-test</a><ul>
<li class="chapter" data-level="21.1" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#when-do-we-use-a-paired-sample-t-test"><i class="fa fa-check"></i><b>21.1</b> When do we use a paired-sample <em>t</em>-test?</a></li>
<li class="chapter" data-level="21.2" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#why-do-we-use-a-paired-sample-design"><i class="fa fa-check"></i><b>21.2</b> Why do we use a paired-sample design?</a></li>
<li class="chapter" data-level="21.3" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#how-do-you-carry-out-a-t-test-on-paired-samples"><i class="fa fa-check"></i><b>21.3</b> How do you carry out a <em>t</em>-test on paired-samples?</a><ul>
<li class="chapter" data-level="21.3.1" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#assumptions-of-the-paired-sample-t-test"><i class="fa fa-check"></i><b>21.3.1</b> Assumptions of the paired-sample <em>t</em>-test</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#carrying-out-a-paired-sample-t-test-in-r"><i class="fa fa-check"></i><b>21.4</b> Carrying out a paired-sample <em>t</em>-test in R</a><ul>
<li class="chapter" data-level="21.4.1" data-path="paired-sample-t-test.html"><a href="paired-sample-t-test.html#using-the-paired-true-argument"><i class="fa fa-check"></i><b>21.4.1</b> Using the <code>paired = TRUE</code> argument</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html"><i class="fa fa-check"></i><b>22</b> ANOVA for randomised block designs</a><ul>
<li class="chapter" data-level="22.1" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#randomized-complete-block-designs"><i class="fa fa-check"></i><b>22.1</b> Randomized Complete Block Designs</a></li>
<li class="chapter" data-level="22.2" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#designs-without-replication"><i class="fa fa-check"></i><b>22.2</b> Designs without replication</a></li>
<li class="chapter" data-level="22.3" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#analysing-an-rcbd-experiment"><i class="fa fa-check"></i><b>22.3</b> Analysing an RCBD experiment</a></li>
<li class="chapter" data-level="22.4" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#carrying-out-the-analysis-with-r"><i class="fa fa-check"></i><b>22.4</b> Carrying out the analysis with R</a><ul>
<li class="chapter" data-level="22.4.1" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#multiple-comparisons-anyone"><i class="fa fa-check"></i><b>22.4.1</b> Multiple comparisons anyone?</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#are-there-disadvantages-to-randomised-block-designs"><i class="fa fa-check"></i><b>22.5</b> Are there disadvantages to randomised block designs?</a></li>
<li class="chapter" data-level="22.6" data-path="anova-for-randomised-block-designs.html"><a href="anova-for-randomised-block-designs.html#multiple-blocking-factors"><i class="fa fa-check"></i><b>22.6</b> Multiple blocking factors</a></li>
</ul></li>
<li class="part"><span><b>VII Beyond Simple Models</b></span></li>
<li class="chapter" data-level="23" data-path="introduction-to-two-way-anova.html"><a href="introduction-to-two-way-anova.html"><i class="fa fa-check"></i><b>23</b> Introduction to two-way ANOVA</a><ul>
<li class="chapter" data-level="23.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="introduction-to-two-way-anova.html"><a href="introduction-to-two-way-anova.html#degrees-of-freedom-mean-squares-and-f-statistics"><i class="fa fa-check"></i><b>23.2</b> Degrees of freedom, mean squares, and <em>F</em>-statistics</a></li>
<li class="chapter" data-level="23.3" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#multiple-comparison-tests"><i class="fa fa-check"></i><b>23.3</b> Multiple comparison tests</a></li>
<li class="chapter" data-level="23.4" data-path="introduction-to-two-way-anova.html"><a href="introduction-to-two-way-anova.html#beyond-two-way-anova"><i class="fa fa-check"></i><b>23.4</b> Beyond two-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html"><i class="fa fa-check"></i><b>24</b> Two-way ANOVA in R</a><ul>
<li class="chapter" data-level="24.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>24.1</b> Introduction</a></li>
<li class="chapter" data-level="24.2" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#competition-between-calluna-and-festuca"><i class="fa fa-check"></i><b>24.2</b> Competition between <em>Calluna</em> and <em>Festuca</em></a></li>
<li class="chapter" data-level="24.3" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#visualising-the-data"><i class="fa fa-check"></i><b>24.3</b> Visualising the data</a></li>
<li class="chapter" data-level="24.4" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#fitting-the-anova-model"><i class="fa fa-check"></i><b>24.4</b> Fitting the ANOVA model</a></li>
<li class="chapter" data-level="24.5" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#diagnostics"><i class="fa fa-check"></i><b>24.5</b> Diagnostics</a></li>
<li class="chapter" data-level="24.6" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#interpreting-the-results"><i class="fa fa-check"></i><b>24.6</b> Interpreting the results</a><ul>
<li class="chapter" data-level="24.6.1" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#understanding-the-model-graphically"><i class="fa fa-check"></i><b>24.6.1</b> Understanding the model graphically</a></li>
</ul></li>
<li class="chapter" data-level="24.7" data-path="multiple-comparison-tests.html"><a href="multiple-comparison-tests.html#multiple-comparison-tests"><i class="fa fa-check"></i><b>24.7</b> Multiple comparison tests</a></li>
<li class="chapter" data-level="24.8" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#drawing-conclusions-and-presenting-results"><i class="fa fa-check"></i><b>24.8</b> Drawing conclusions and presenting results</a><ul>
<li class="chapter" data-level="24.8.1" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#a-little-more-customisation"><i class="fa fa-check"></i><b>24.8.1</b> A little more customisation</a></li>
</ul></li>
<li class="chapter" data-level="24.9" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#balanced-or-orthogonal-designs"><i class="fa fa-check"></i><b>24.9</b> Balanced or orthogonal designs</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="introduction-to-ancova.html"><a href="introduction-to-ancova.html"><i class="fa fa-check"></i><b>25</b> Introduction to ANCOVA</a><ul>
<li class="chapter" data-level="25.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>25.1</b> Introduction</a></li>
<li class="chapter" data-level="25.2" data-path="introduction-to-ancova.html"><a href="introduction-to-ancova.html#why-do-we-need-ancova-models"><i class="fa fa-check"></i><b>25.2</b> Why do we need ANCOVA models?</a></li>
<li class="chapter" data-level="25.3" data-path="introduction-to-ancova.html"><a href="introduction-to-ancova.html#how-does-ancova-work"><i class="fa fa-check"></i><b>25.3</b> How does ANCOVA work?</a></li>
<li class="chapter" data-level="25.4" data-path="introduction-to-two-way-anova.html"><a href="introduction-to-two-way-anova.html#degrees-of-freedom-mean-squares-and-f-statistics"><i class="fa fa-check"></i><b>25.4</b> Degrees of freedom, mean squares and F-statistics</a></li>
<li class="chapter" data-level="25.5" data-path="introduction-to-ancova.html"><a href="introduction-to-ancova.html#assumptions-of-ancova"><i class="fa fa-check"></i><b>25.5</b> Assumptions of ANCOVA</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="two-way-ancova-in-r.html"><a href="two-way-ancova-in-r.html"><i class="fa fa-check"></i><b>26</b> Two-way ANCOVA in R</a><ul>
<li class="chapter" data-level="26.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>26.1</b> Introduction</a></li>
<li class="chapter" data-level="26.2" data-path="simple-regression-in-r.html"><a href="simple-regression-in-r.html#visualising-the-data"><i class="fa fa-check"></i><b>26.2</b> Visualising the data</a></li>
<li class="chapter" data-level="26.3" data-path="two-way-ancova-in-r.html"><a href="two-way-ancova-in-r.html#fitting-an-ancova"><i class="fa fa-check"></i><b>26.3</b> Fitting an ANCOVA</a></li>
<li class="chapter" data-level="26.4" data-path="two-way-anova-in-r.html"><a href="two-way-anova-in-r.html#diagnostics"><i class="fa fa-check"></i><b>26.4</b> Diagnostics</a></li>
<li class="chapter" data-level="26.5" data-path="one-way-anova-in-r.html"><a href="one-way-anova-in-r.html#interpreting-the-results"><i class="fa fa-check"></i><b>26.5</b> Interpreting the results</a></li>
<li class="chapter" data-level="26.6" data-path="two-way-ancova-in-r.html"><a href="two-way-ancova-in-r.html#presenting-the-results"><i class="fa fa-check"></i><b>26.6</b> Presenting the results</a></li>
</ul></li>
<li class="part"><span><b>VIII Frequency Data and Non-parametric Tests</b></span></li>
<li class="chapter" data-level="27" data-path="working-with-frequencies.html"><a href="working-with-frequencies.html"><i class="fa fa-check"></i><b>27</b> Working with frequencies</a><ul>
<li class="chapter" data-level="27.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>27.1</b> Introduction</a></li>
<li class="chapter" data-level="27.2" data-path="working-with-frequencies.html"><a href="working-with-frequencies.html#a-new-kind-of-distribution"><i class="fa fa-check"></i><b>27.2</b> A new kind of distribution</a></li>
<li class="chapter" data-level="27.3" data-path="working-with-frequencies.html"><a href="working-with-frequencies.html#types-of-test"><i class="fa fa-check"></i><b>27.3</b> Types of test</a><ul>
<li class="chapter" data-level="27.3.1" data-path="working-with-frequencies.html"><a href="working-with-frequencies.html#chi2-goodness-of-fit-test"><i class="fa fa-check"></i><b>27.3.1</b> <span class="math inline">\(\chi^{2}\)</span> goodness of fit test</a></li>
<li class="chapter" data-level="27.3.2" data-path="working-with-frequencies.html"><a href="working-with-frequencies.html#chi2-contingency-table-test"><i class="fa fa-check"></i><b>27.3.2</b> <span class="math inline">\(\chi^{2}\)</span> contingency table test</a></li>
<li class="chapter" data-level="27.3.3" data-path="working-with-frequencies.html"><a href="working-with-frequencies.html#the-assumptions-and-requirements-of-chi2-tests"><i class="fa fa-check"></i><b>27.3.3</b> The assumptions and requirements of <span class="math inline">\(\chi^{2}\)</span> tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html"><i class="fa fa-check"></i><b>28</b> Goodness of fit tests</a><ul>
<li class="chapter" data-level="28.1" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#when-do-we-use-a-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>28.1</b> When do we use a chi-square goodness of fit test?</a></li>
<li class="chapter" data-level="28.2" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#how-does-the-chi-square-goodness-of-fit-test-work"><i class="fa fa-check"></i><b>28.2</b> How does the chi-square goodness of fit test work?</a><ul>
<li class="chapter" data-level="28.2.1" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#assumptions-of-the-chi-square-goodness-of-fit-test"><i class="fa fa-check"></i><b>28.2.1</b> Assumptions of the chi-square goodness of fit test</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#carrying-out-a-chi-square-goodness-of-fit-test-in-r"><i class="fa fa-check"></i><b>28.3</b> Carrying out a chi-square goodness of fit test in R</a><ul>
<li class="chapter" data-level="28.3.1" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#summarising-the-result"><i class="fa fa-check"></i><b>28.3.1</b> Summarising the result</a></li>
<li class="chapter" data-level="28.3.2" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#a-bit-more-about-goodness-of-fit-tests-in-r"><i class="fa fa-check"></i><b>28.3.2</b> A bit more about goodness of fit tests in R</a></li>
<li class="chapter" data-level="28.3.3" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#doing-it-the-long-way"><i class="fa fa-check"></i><b>28.3.3</b> Doing it the long way…</a></li>
</ul></li>
<li class="chapter" data-level="28.4" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#determining-appropriate-expected-values"><i class="fa fa-check"></i><b>28.4</b> Determining appropriate expected values</a></li>
</ul></li>
<li class="chapter" data-level="29" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>29</b> Contingency tables</a><ul>
<li class="chapter" data-level="29.1" data-path="contingency-tables.html"><a href="contingency-tables.html#when-do-we-use-a-chi-square-contingency-table-test"><i class="fa fa-check"></i><b>29.1</b> When do we use a chi-square contingency table test?</a></li>
<li class="chapter" data-level="29.2" data-path="contingency-tables.html"><a href="contingency-tables.html#how-does-the-chi-square-contingency-table-test-work"><i class="fa fa-check"></i><b>29.2</b> How does the chi-square contingency table test work?</a><ul>
<li class="chapter" data-level="29.2.1" data-path="contingency-tables.html"><a href="contingency-tables.html#assumptions-of-the-chi-square-contingency-table-test"><i class="fa fa-check"></i><b>29.2.1</b> Assumptions of the chi-square contingency table test</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="contingency-tables.html"><a href="contingency-tables.html#carrying-out-a-chi-square-contingency-table-test-in-r"><i class="fa fa-check"></i><b>29.3</b> Carrying out a chi-square contingency table test in R</a><ul>
<li class="chapter" data-level="29.3.1" data-path="contingency-tables.html"><a href="contingency-tables.html#step-1.-getting-the-data-into-the-correct-format"><i class="fa fa-check"></i><b>29.3.1</b> Step 1. Getting the data into the correct format</a></li>
<li class="chapter" data-level="29.3.2" data-path="contingency-tables.html"><a href="contingency-tables.html#step-2.-doing-the-test"><i class="fa fa-check"></i><b>29.3.2</b> Step 2. Doing the test</a></li>
<li class="chapter" data-level="29.3.3" data-path="goodness-of-fit-tests.html"><a href="goodness-of-fit-tests.html#summarising-the-result"><i class="fa fa-check"></i><b>29.3.3</b> Summarising the result</a></li>
</ul></li>
<li class="chapter" data-level="29.4" data-path="contingency-tables.html"><a href="contingency-tables.html#working-with-larger-tables"><i class="fa fa-check"></i><b>29.4</b> Working with larger tables</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html"><i class="fa fa-check"></i><b>30</b> Non-parametric tests</a><ul>
<li class="chapter" data-level="30.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#what-is-non-par"><i class="fa fa-check"></i><b>30.1</b> What is a non-parametric test?</a></li>
<li class="chapter" data-level="30.2" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#non-par-intro"><i class="fa fa-check"></i><b>30.2</b> How does a non-parametric test work?</a></li>
<li class="chapter" data-level="30.3" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#non-parametric-equivalents"><i class="fa fa-check"></i><b>30.3</b> Non-parametric equivalents</a></li>
<li class="chapter" data-level="30.4" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>30.4</b> Wilcoxon signed-rank test</a><ul>
<li class="chapter" data-level="30.4.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#leaf-damage-plant-defences-and-feeding-by-winter-moth-larvae"><i class="fa fa-check"></i><b>30.4.1</b> Leaf damage, plant defences and feeding by winter moth larvae</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#mann-whitney"><i class="fa fa-check"></i><b>30.5</b> The Mann-Whitney <em>U</em>-test</a><ul>
<li class="chapter" data-level="30.5.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#ant-foraging"><i class="fa fa-check"></i><b>30.5.1</b> Ant foraging</a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#the-kruskal-wallis-test"><i class="fa fa-check"></i><b>30.6</b> The Kruskal-Wallis test</a><ul>
<li class="chapter" data-level="30.6.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#learning-in-cuttlefish"><i class="fa fa-check"></i><b>30.6.1</b> Learning in cuttlefish</a></li>
</ul></li>
<li class="chapter" data-level="30.7" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#spearmans-rank-correlation"><i class="fa fa-check"></i><b>30.7</b> Spearman’s rank correlation</a><ul>
<li class="chapter" data-level="30.7.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#grouse-lekking"><i class="fa fa-check"></i><b>30.7.1</b> Grouse lekking</a></li>
</ul></li>
<li class="chapter" data-level="30.8" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#why-when"><i class="fa fa-check"></i><b>30.8</b> Why use non-parametric tests … and when?</a><ul>
<li class="chapter" data-level="30.8.1" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#what-are-the-advantages"><i class="fa fa-check"></i><b>30.8.1</b> What are the advantages?</a></li>
<li class="chapter" data-level="30.8.2" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#what-are-the-disadvantages"><i class="fa fa-check"></i><b>30.8.2</b> What are the disadvantages?</a></li>
<li class="chapter" data-level="30.8.3" data-path="non-parametric-tests.html"><a href="non-parametric-tests.html#parting-words"><i class="fa fa-check"></i><b>30.8.3</b> Parting words</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Supplementary Material</b></span></li>
<li class="chapter" data-level="A" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html"><i class="fa fa-check"></i><b>A</b> Choosing models and tests</a><ul>
<li class="chapter" data-level="A.1" data-path="introduction-to-one-way-anova.html"><a href="introduction-to-one-way-anova.html#intro"><i class="fa fa-check"></i><b>A.1</b> Introduction</a><ul>
<li class="chapter" data-level="A.1.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#do-we-need-to-carry-out-a-statistical-analysis"><i class="fa fa-check"></i><b>A.1.1</b> Do we need to carry out a statistical analysis?</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#getting-started"><i class="fa fa-check"></i><b>A.2</b> Getting started…</a></li>
<li class="chapter" data-level="A.3" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#a-key-to-choosing-statistical-models-and-tests"><i class="fa fa-check"></i><b>A.3</b> A key to choosing statistical models and tests</a></li>
<li class="chapter" data-level="A.4" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#four-questions"><i class="fa fa-check"></i><b>A.4</b> Four main types of question</a></li>
<li class="chapter" data-level="A.5" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#qu1"><i class="fa fa-check"></i><b>A.5</b> Question 1 –- Comparison of group means or medians</a><ul>
<li class="chapter" data-level="A.5.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-how-many-groups"><i class="fa fa-check"></i><b>A.5.1</b> Question 1 How many groups?</a></li>
<li class="chapter" data-level="A.5.2" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-single-group"><i class="fa fa-check"></i><b>A.5.2</b> [Question 1] Single group</a></li>
<li class="chapter" data-level="A.5.3" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-two-groups"><i class="fa fa-check"></i><b>A.5.3</b> [Question 1] Two groups</a></li>
<li class="chapter" data-level="A.5.4" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-1-more-than-two-groups"><i class="fa fa-check"></i><b>A.5.4</b> [Question 1] More than two groups</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#qu2"><i class="fa fa-check"></i><b>A.6</b> Question 2 – Associations between two variables?</a><ul>
<li class="chapter" data-level="A.6.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#question-2-testing-y-as-a-function-of-x-or-an-association-between-x-and-y"><i class="fa fa-check"></i><b>A.6.1</b> [Question 2] Testing <span class="math inline">\(y\)</span> as a function of <span class="math inline">\(x\)</span>, or an association between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>?</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#qu4"><i class="fa fa-check"></i><b>A.7</b> Question 3 -– Frequencies of categorical data</a></li>
<li class="chapter" data-level="A.8" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#var-cat"><i class="fa fa-check"></i><b>A.8</b> Variables or categories?</a><ul>
<li class="chapter" data-level="A.8.1" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#anova-vs.-regression"><i class="fa fa-check"></i><b>A.8.1</b> ANOVA vs. regression</a></li>
<li class="chapter" data-level="A.8.2" data-path="choosing-models-and-tests.html"><a href="choosing-models-and-tests.html#making-categories-out-of-continuous-measures"><i class="fa fa-check"></i><b>A.8.2</b> Making categories out of continuous measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html"><i class="fa fa-check"></i><b>B</b> Writing a scientific report</a><ul>
<li class="chapter" data-level="B.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>B.1</b> Introduction</a></li>
<li class="chapter" data-level="B.2" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#the-structure-of-a-scientific-report"><i class="fa fa-check"></i><b>B.2</b> The structure of a scientific report</a><ul>
<li class="chapter" data-level="B.2.1" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#title"><i class="fa fa-check"></i><b>B.2.1</b> Title</a></li>
<li class="chapter" data-level="B.2.2" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#abstract-or-summary"><i class="fa fa-check"></i><b>B.2.2</b> Abstract or Summary</a></li>
<li class="chapter" data-level="B.2.3" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#introduction-1"><i class="fa fa-check"></i><b>B.2.3</b> Introduction</a></li>
<li class="chapter" data-level="B.2.4" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#methods"><i class="fa fa-check"></i><b>B.2.4</b> Methods</a></li>
<li class="chapter" data-level="B.2.5" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#results"><i class="fa fa-check"></i><b>B.2.5</b> Results</a></li>
<li class="chapter" data-level="B.2.6" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#discussion"><i class="fa fa-check"></i><b>B.2.6</b> Discussion</a></li>
<li class="chapter" data-level="B.2.7" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#acknowledgements"><i class="fa fa-check"></i><b>B.2.7</b> Acknowledgements</a></li>
<li class="chapter" data-level="B.2.8" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#literature-cited-references"><i class="fa fa-check"></i><b>B.2.8</b> Literature cited / References</a></li>
<li class="chapter" data-level="B.2.9" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#appendices"><i class="fa fa-check"></i><b>B.2.9</b> Appendices</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#presenting-species-names"><i class="fa fa-check"></i><b>B.3</b> Presenting species names</a><ul>
<li class="chapter" data-level="B.3.1" data-path="writing-a-scientific-report.html"><a href="writing-a-scientific-report.html#a-last-piece-of-advice"><i class="fa fa-check"></i><b>B.3.1</b> A last piece of advice…</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="principles-of-experimental-design.html"><a href="principles-of-experimental-design.html#further-reading"><i class="fa fa-check"></i><b>B.4</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="one-tailed-vs-two-tailed-tests.html"><a href="one-tailed-vs-two-tailed-tests.html"><i class="fa fa-check"></i><b>C</b> One-tailed vs. two-tailed tests</a><ul>
<li class="chapter" data-level="C.1" data-path="parametric-statistics.html"><a href="parametric-statistics.html#introduction"><i class="fa fa-check"></i><b>C.1</b> Introduction</a></li>
<li class="chapter" data-level="C.2" data-path="one-tailed-vs-two-tailed-tests.html"><a href="one-tailed-vs-two-tailed-tests.html#an-example-of-a-one-tailed-hypothesis"><i class="fa fa-check"></i><b>C.2</b> An example of a one-tailed hypothesis</a></li>
<li class="chapter" data-level="C.3" data-path="one-tailed-vs-two-tailed-tests.html"><a href="one-tailed-vs-two-tailed-tests.html#so-how-do-we-perform-a-one-tailed-t-test"><i class="fa fa-check"></i><b>C.3</b> So how do we perform a one-tailed <em>t</em>-test?</a><ul>
<li class="chapter" data-level="C.3.1" data-path="one-tailed-vs-two-tailed-tests.html"><a href="one-tailed-vs-two-tailed-tests.html#carrying-out-one-tailed-t-tests-in-r"><i class="fa fa-check"></i><b>C.3.1</b> Carrying out one-tailed <em>t</em>-tests in R</a></li>
<li class="chapter" data-level="C.3.2" data-path="one-tailed-vs-two-tailed-tests.html"><a href="one-tailed-vs-two-tailed-tests.html#when-to-use-and-not-to-use-one-tailed-t-tests"><i class="fa fa-check"></i><b>C.3.2</b> When to use, and not to use, one-tailed <em>t</em>-tests</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis and Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="non-parametric-tests" class="section level1">
<h1><span class="header-section-number">Chapter 30</span> Non-parametric tests</h1>
<div id="what-is-non-par" class="section level2">
<h2><span class="header-section-number">30.1</span> What is a non-parametric test?</h2>
<p>The majority of procedures we have been using to evaluate statistical significance require various assumptions about population distributions to be satisfied. These are referred to as parametric methods because they are underpinned by a mathematical model of the population(s) (we discussed this idea in the [Parametric statistics] chapter). For this reason, the statistical tests associated with these methods—e.g. global significance tests and multiple comparisons tests in ANOVA—are called <strong>parametric tests</strong>.</p>
<p><strong>Non-parametric tests</strong> are a class of statistical tests that make much weaker assumptions. The advantage of non-parametric tests is that they can be employed with a much wider range of forms of data than their parametric cousins. Although non-parametric tests are less restrictive in their assumptions, they are not, as is sometimes stated, assumption-free. The term non-parametric is just a catch-all term that applies to any test which doesn’t assume the data are drawn from a <em>specific</em> distribution. We have already seen a number of examples of non-parametric tests:</p>
<ul>
<li><p>The bootstrap and permutation test procedures introduced in the first few chapters are non-parametric techniques.</p></li>
<li><p>The <span class="math inline">\(\chi^{2}\)</span> goodness of fit and the <span class="math inline">\(\chi^{2}\)</span> contingency table tests make weak assumptions about the frequency data.</p></li>
</ul>
<p>In this chapter we are going to look at non-parametric tests which perform analyses equivalent to <em>t</em>-tests, correlation, and the global significance test in one-way ANOVA.</p>
</div>
<div id="non-par-intro" class="section level2">
<h2><span class="header-section-number">30.2</span> How does a non-parametric test work?</h2>
<p>The key thing about the non-parametric tests we’ll consider here is that the calculations are done using the rank order of the data, whatever the type of the original data-–-ratio, interval, or ordinal.</p>
<p>The general principle of such a test can be easily illustrated with the following example. Imagine that we want to compare two samples to determine whether they differ in their central tendency. That is, we want to know if the values in one sample tend to be larger or smaller than the values in a second sample. For example…</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Sample A:</td>
<td align="center">1.3</td>
<td align="center">2.8</td>
<td align="center">4.1</td>
<td align="center">3.2</td>
</tr>
<tr class="even">
<td align="left">Sample B:</td>
<td align="center">7.2</td>
<td align="center">3.0</td>
<td align="center">4.2</td>
<td align="center">6.2</td>
</tr>
</tbody>
</table>
<p>If all the data (i.e. from both samples) are put in ascending order…</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Sample A:</td>
<td align="center">1.3</td>
<td align="center">2.8</td>
<td></td>
<td align="center">3.2</td>
<td align="center">4.1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td align="left">Sample B:</td>
<td align="center"></td>
<td align="center"></td>
<td>3.0</td>
<td align="center"></td>
<td align="center"></td>
<td>4.2</td>
<td>6.2</td>
<td>7.2</td>
</tr>
</tbody>
</table>
<p>Then each number can be given a rank according to its place in the ordering…</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Sample A:</td>
<td align="center">1</td>
<td align="center">2</td>
<td></td>
<td align="center">4</td>
<td align="center">5</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td align="left">Sample B:</td>
<td align="center"></td>
<td align="center"></td>
<td>3</td>
<td align="center"></td>
<td align="center"></td>
<td>6</td>
<td>7</td>
<td>8</td>
</tr>
</tbody>
</table>
<p>It is easy to see now that if the rank values from each sample are added up Sample A will have a lower value (sum = 12) than Sample B (sum = 24). This suggests that sample B has larger values than sample A.</p>
<p>If the samples had been completely non-overlapping the totals would have been…</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Sample A:</td>
<td align="center">1 +</td>
<td align="center">2 +</td>
<td align="center">3 +</td>
<td align="center">4</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td align="left">= 10</td>
</tr>
<tr class="even">
<td align="left">Sample B:</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td>5 +</td>
<td>6 +</td>
<td>7 +</td>
<td>8</td>
<td align="left">= 26</td>
</tr>
</tbody>
</table>
<p>On the other hand, if the samples had been largely overlapping the rank totals would have been equal, or close to it…</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Sample A:</td>
<td align="center">1 +</td>
<td></td>
<td></td>
<td align="center">4 +</td>
<td></td>
<td align="center">6 +</td>
<td align="center">7</td>
<td></td>
<td align="left">= 18</td>
</tr>
<tr class="even">
<td align="left">Sample B:</td>
<td align="center"></td>
<td>2 +</td>
<td>3 +</td>
<td align="center"></td>
<td>5 +</td>
<td align="center"></td>
<td align="center"></td>
<td>8</td>
<td align="left">= 18</td>
</tr>
</tbody>
</table>
<p>Obviously, the greater the difference in the rank totals the less likely it is that the two samples could have come from the same distribution of values—i.e. the more likely it is that difference between them may be statistically significant.</p>
<p>The important thing to notice in such a procedure is that the original data could have been replaced with quite different values which, provided the ordering was the same, would have given exactly the same result. In other words the outcome of the test is reasonably insensitive to the underlying distribution of the data.</p>
</div>
<div id="non-parametric-equivalents" class="section level2">
<h2><span class="header-section-number">30.3</span> Non-parametric equivalents</h2>
<p>There are several non-parametric procedures (all available in R) which provide similar types of test to the simple parametric tests we have seen already. The actual calculations for the different tests are a little more involved than the general outline above, but they work from the same basic principle: find the rank order of all the data, and then use the ranks in different groups to assess the statistical significance of the observed differences. As always, we have to specify some kind of null hypothesis (e.g. the medians of two samples are the same) to make the significance calculation work.</p>
<p>The four tests discussed here are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Wilcoxon signed-rank test</strong>: The test is equivalent to a one-sample and paired-sample <em>t</em>-test. This test also goes by the name of the Wilcoxon one-sample test, the Wilcoxon matched-pairs test, the Wilcoxon paired-sample test. It can be used to…</p>
<ul>
<li>compare a sample to a single value, or</li>
<li>test for differences between paired samples.</li>
</ul></li>
<li><p><strong>Mann-Whitney <em>U</em>-test</strong>: This is equivalent to the two-sample <em>t</em>-test. It tests for differences between two unpaired samples. This test also goes by the name of the Wilcoxon two-sample test, the Mann–Whitney–Wilcoxon, Wilcoxon rank-sum test.</p></li>
<li><p><strong>Kruskal-Wallis test</strong>: tests for differences between several samples. This is equivalent to a one-way analysis of variance.</p></li>
<li><p><strong>Spearman’s Rank correlation</strong>: tests for an association between two variables. This is equivalent to Pearson’s correlation.</p></li>
</ol>
<p>Notice that we haven’t said anything about <em>what kind</em> of differences among samples these evaluate, i.e. we didn’t specify the null hypothesis. We’ll address this question as we discuss each test.</p>
</div>
<div id="wilcoxon-signed-rank-test" class="section level2">
<h2><span class="header-section-number">30.4</span> Wilcoxon signed-rank test</h2>
<p>The most widely used non-parametric equivalent to the one-sample <em>t</em>-test is the Wilcoxon signed-rank test. The test can be used for any situation requiring a test to compare the median of a sample against a single value. However, it is almost always used to analyse data collected using a paired-sample design, so we’ll focus on that particular application of the test. The Wilcoxon signed-rank test makes less stringent assumptions than the <em>t</em>-test, but it does make some assumptions:</p>
<ul>
<li><p>The variable being tested is measured on ordinal, interval, or ratio scales</p></li>
<li><p>The (population) distribution of the variable is approximately symmetric<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>.</p></li>
</ul>
<p>The first assumption is simple enough—the variable can be anything but nominal. The second assumption essentially means that it doesn’t matter what form the distribution of the variable looks like as long as it is symmetric—it would not be satisfied if the distribution were strongly right- or left-skewed.</p>
<p>As with the <em>t</em>-test, when applied to paired-sample data the Wilcoxon signed-rank test starts by finding the differences between all the pairs, and then tests whether these differences are significantly different form zero. The distribution under consideration is the <em>distribution of differences</em> between the pairs. Remember, this distribution will often be approximately normal even when the connected samples are not themselves drawn from a normal distribution. This means that even if the samples have odd distributions, we may still find that we can use a paired-sample <em>t</em>-test if differences have a perfectly acceptable distribution. However, if the distribution of differences is not normal then the Wilcoxon signed-rank test provides an alternative.</p>
<p>The following is an example of a situation where the Wilcoxon signed-rank test would be appropriate.</p>
<div id="leaf-damage-plant-defences-and-feeding-by-winter-moth-larvae" class="section level3">
<h3><span class="header-section-number">30.4.1</span> Leaf damage, plant defences and feeding by winter moth larvae</h3>
<p>It has been hypothesised that plants respond to physical damage to their leaves from herbivores such as lepidopteran larvae by increasing production of defensive compounds such as phenolics. In an experiment to test this effect, birch saplings were subjected to artificial leaf damage (hole punching) on half the leaves on selected branches. After 24 h undamaged leaves from both the branches with hole-punched leaves and others distant from the damage site were collected and used in a choice test experiment with winter moth larvae. Twenty trials were carried out with a single caterpillar in each trial, offered one of each type of leaf (i.e. one leaf from close to the damage site and one from an undamaged area). The percentage of each leaf consumed was estimated (to the nearest 5%) after 24h.</p>
<p>The data are in the file LEAF_DAMAGE.CSV:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="non-parametric-tests.html#cb276-1"></a>leaves &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file=</span><span class="st">&quot;LEAF_DAMAGE.CSV&quot;</span>)</span>
<span id="cb276-2"><a href="non-parametric-tests.html#cb276-2"></a><span class="kw">glimpse</span>(leaves)</span></code></pre></div>
<pre><code>## Rows: 40
## Columns: 3
## $ ID       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...
## $ LeafType &lt;chr&gt; &quot;Notdamaged&quot;, &quot;Notdamaged&quot;, &quot;Notdamaged&quot;, &quot;Notdamaged&quot;, &quot;N...
## $ Damage   &lt;int&gt; 65, 0, 10, 45, 55, 45, 0, 10, 5, 70, 55, 40, 0, 70, 65, 35...</code></pre>
<p>There are three variables: <code>ID</code> contains a unique identifier for each pair of leaves in a trial (1-20), <code>Leaf</code> identifies the type of leaf (‘Damaged’ vs. ‘Undamaged’), and <code>Damage</code> contains the percent damage score. As always, it’s a good idea to visualise the data:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="non-parametric-tests.html#cb278-1"></a>jitter_leaves &lt;-<span class="st"> </span><span class="kw">mutate</span>(leaves, <span class="dt">Damage =</span> <span class="kw">jitter</span>(Damage, <span class="dt">factor =</span> <span class="dv">4</span>))</span>
<span id="cb278-2"><a href="non-parametric-tests.html#cb278-2"></a><span class="kw">ggplot</span>(jitter_leaves, <span class="kw">aes</span>(<span class="dt">x =</span> LeafType, <span class="dt">y =</span> Damage, <span class="dt">group =</span> ID)) <span class="op">+</span></span>
<span id="cb278-3"><a href="non-parametric-tests.html#cb278-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() </span></code></pre></div>
<p><img src="stats-for-bio_files/figure-html/winter-moth-damage-1.png" width="288" style="display: block; margin: auto;" /></p>
<p>It’s not critical to learn it, but we used a new trick here: using <code>mutate</code>, we ‘jittered’ the <code>Damage</code> values (with the <code>jitter</code> function) to deal with the overplotting. This adds a bit of random noise to the values so that those with the same values end up being plotted in different highlights two features of the data: 1) There is plenty of variation (some larvae just eat more than others), 2) there is a tendency for larvae to prefer the undamaged leaves, though the pattern is not overwhelming.</p>
<p>Obviously we need a statistical test—a paired sample <em>t</em>-test or a Wilcoxon signed-rank test are our two options. We should also visualise this distribution of <em>within larvae</em> differences to determine whether or not we need to use a Wilcoxon signed-rank test:</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="non-parametric-tests.html#cb279-1"></a><span class="co"># step 1 -- calculate the differences</span></span>
<span id="cb279-2"><a href="non-parametric-tests.html#cb279-2"></a>leaves_diff &lt;-<span class="st"> </span></span>
<span id="cb279-3"><a href="non-parametric-tests.html#cb279-3"></a><span class="st">  </span>leaves <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb279-4"><a href="non-parametric-tests.html#cb279-4"></a><span class="st">  </span><span class="kw">group_by</span>(ID) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb279-5"><a href="non-parametric-tests.html#cb279-5"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">DiffDamage =</span> <span class="kw">diff</span>(Damage))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="non-parametric-tests.html#cb281-1"></a><span class="co"># step 2 -- make the plot</span></span>
<span id="cb281-2"><a href="non-parametric-tests.html#cb281-2"></a><span class="kw">ggplot</span>(leaves_diff, <span class="kw">aes</span>(<span class="dt">x =</span> DiffDamage)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb281-3"><a href="non-parametric-tests.html#cb281-3"></a><span class="st">  </span><span class="kw">geom_dotplot</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>)</span></code></pre></div>
<p><img src="stats-for-bio_files/figure-html/winter-moth-damage-diff-1.png" width="288" style="display: block; margin: auto;" />
There are large differences in both directions and the distribution does not seem to be normal (it is very ‘flat’). The problem here is that caterpillars often spend time feeding on the first leaf they encounter, which is a more or less random choice; some may change leaves in quickly in response to the quality of the leaf, others may feed for sometime before leaving the leaf. We might still expect those on better defended leaves to feed less, as the leaves should be less palatable, but they may not make the behavioural decision to leave the leaf during the short period of the experiment (the experiment cannot go on for longer because the leaves change chemically the longer they are detached from the plant)</p>
<p>The distribution may not be normal, but it is roughly symmetrical. The symmetry assumption of the Wilcoxon signed-rank test seems to be satisfied, so we can use this test to examine whether there is any difference in caterpillar feeding on leaves from damaged areas and undamaged areas. We carry out the test using the <code>wilcox.test</code> function in R<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. This is used in exactly the same way as the <code>t.test</code> function for a paired-sample design:</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="non-parametric-tests.html#cb282-1"></a><span class="kw">wilcox.test</span>(Damage <span class="op">~</span><span class="st"> </span>LeafType, <span class="dt">paired =</span> <span class="ot">TRUE</span>, <span class="dt">data =</span> leaves)</span></code></pre></div>
<pre><code>## Warning in wilcox.test.default(x = c(5L, 25L, 30L, 40L, 15L, 5L, 35L, 45L, :
## cannot compute exact p-value with ties</code></pre>
<pre><code>## Warning in wilcox.test.default(x = c(5L, 25L, 30L, 40L, 15L, 5L, 35L, 45L, :
## cannot compute exact p-value with zeroes</code></pre>
<pre><code>## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  Damage by LeafType
## V = 50.5, p-value = 0.07617
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>We must remember to set <code>paired = TRUE</code>. If we forget to do this R will carry out the two-sample version of the test (the Mann-Whitney <em>U</em>-test discussed next). R produces a couple of warning here but we can usually ignore these—we can’t do much about them even if we wanted to.</p>
<p>The elements of the output should be fairly easy to understand by now. At the top we see a summary of the test and the data:</p>
<pre><code>##        Wilcoxon rank sum test with continuity correction
## data:  Damage by LeafType</code></pre>
<p>Next, we see the results: a test statistic and <em>p</em>-value. Although the test statistic is given as ‘V’ in the output, it is often quoted as ‘W’ when writing it in a report (we’ll adopt this convention). This seems a bit odd, but it stems from the fact that there is some variation in the literature about what we report, and how to report, non-parametric tests.</p>
<p>The <em>p</em>-value is close to <em>p</em> = 0.05, but it doesn’t quite fall below the threshold. It looks like there is no significant difference in feeding rates on the two types of leaf. We might report this as:</p>
<blockquote>
<p>When given a choice, winter moth larvae did not consume larger amounts of the leaves collected from areas of the tree that are undamaged than those from damaged areas (Wilcoxon matched-pairs test: W = 139.5, n = 20, p = 0.076).</p>
</blockquote>
</div>
</div>
<div id="mann-whitney" class="section level2">
<h2><span class="header-section-number">30.5</span> The Mann-Whitney <em>U</em>-test</h2>
<p>The Mann-Whitney <em>U</em>-test is the non-parametric equivalent to the independent two-sample <em>t</em>-test. The test can be used for any situation requiring a test to compare the median of two samples. The assumptions of the Mann-Whitney <em>U</em>-test are:</p>
<ul>
<li><p>The variable being tested is measured on ordinal, interval, or ratio scales</p></li>
<li><p>The observations from both groups are independent of one another.</p></li>
</ul>
<p>The first two assumptions are straightforward—data can be anything but nominal, and as with a paired-sample <em>t</em>-test, there must not be any dependence between the observations. Though not strictly necessary for the Mann-Whitney <em>U</em>-test to be valid, we usually add a third assumption:</p>
<ul>
<li>The distribution of the variable in each group is similar (apart than the fact that they have a different central tendency)</li>
</ul>
<p>This assumption essentially means that it doesn’t matter what the distributions of the two samples are like, but they should be at least roughly similar—it would not be satisfied if we plan to compare data from a strongly right-skewed distribution with data from a strongly left-skewed distribution. If this assumption is not satisfied the test can still be used, but a significant result is hard to interpret (so don’t bother!).</p>
<p>When all three of the above assumptions are satisfied the Mann-Whitney <em>U</em>-test is used as a way of looking for differences between the central tendency of two distributions. A two-sample <em>t</em>-test evaluates the statistical significance of differences between two means. The null hypothesis of the Mann-Whitney <em>U</em>-test (if all three of the above assumptions) is that the two distributions <em>have the same median</em> . A significant <em>p</em> value therefore indicates that the medians are likely to be different.</p>
<div id="ant-foraging" class="section level3">
<h3><span class="header-section-number">30.5.1</span> Ant foraging</h3>
<p>Let’s use the Red wood ants example from the chapter on transformations to see how to carry out the Mann-Whitney <em>U</em>-test. The data are the file ANTS1.CSV (not ANTS2.CSV!). Recall that this study measured the total biomass of prey being transported—the rate of food collection per ant per half hour—on three different tree species (rowan, sycamore and oak). The <code>Tree</code> variable contains the identities and the <code>Food</code> variable contains the food collection rates. Since we the Mann-Whitney <em>U</em>-test only compares two samples, we will focus on the oak and sycamore here to illustrate the test<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>.</p>
<p>After reading the data into R we need to use the filter function to remove ‘Rowan’ cases:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="non-parametric-tests.html#cb287-1"></a>ants &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;ANTS1.CSV&quot;</span>)</span>
<span id="cb287-2"><a href="non-parametric-tests.html#cb287-2"></a>ants &lt;-<span class="st"> </span><span class="kw">filter</span>(ants, Tree <span class="op">!=</span><span class="st"> &quot;Rowan&quot;</span>)</span></code></pre></div>
<p>The <code>Tree != "Rowan"</code> inside the filter function specifies that we want cases where <code>Tree</code> <em>is not equal to</em> (<code>!=</code>) ‘Rowan’.</p>
<p>Carrying out a Mann-Whitney <em>U</em>-test in R is simple enough, but somewhat confusingly, we have to use the <code>wilcox.test</code> function again. This is because, as we noted above, the Mann-Whitney <em>U</em>-test is also called a <strong>two-sample Wilcoxon test</strong>.</p>
<p>The <code>wilcox.test</code> function for an independent two-sample design works just like the corresponding analysis with the <code>t.test</code> function. The first argument should be a formula, and the second should be the data frame containing the relevant variables:</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="non-parametric-tests.html#cb288-1"></a><span class="kw">wilcox.test</span>(Food <span class="op">~</span><span class="st"> </span>Tree, <span class="dt">data =</span> ants)</span></code></pre></div>
<pre><code>## Warning in wilcox.test.default(x = c(20.1, 47.4, 85.6, 17.1, 5.7, 7.8, 28.8, :
## cannot compute exact p-value with ties</code></pre>
<pre><code>## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  Food by Tree
## W = 453.5, p-value = 0.06955
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>The formula (<code>Food ~ Tree</code>) works in the same way as other statistical function in R: the variable containing the values we wish to compare (<code>Food</code>) is on the left hand side of the <code>~</code> and the variable containing the group identities (<code>Tree</code>) belongs to the right of it.</p>
<p>The output from a Mann-Whitney <em>U</em>-test is similar from that produced by the <code>t.test</code> function. At the top we see a summary of the test and the data:</p>
<pre><code>##         Wilcoxon rank sum test with continuity correction
## data:  Food by Tree</code></pre>
<p>This version of the Wilcoxon test is the same thing as a Mann-Whitney <em>U</em>-test so there is nothing to worry about here. After this line we see a test statistic (’W’ilcoxon) and the associated <em>p</em>-value. Since <em>p</em>=0.07, we conclude the rates of removal of prey biomass were not significantly different between ants foraging in oak and in sycamore. In a report the conclusion from the test can be summarised…</p>
<blockquote>
<p>The rates of removal of prey biomass were not significantly different between ants foraging in oak and in sycamore (Mann-Whitney <em>U</em>-test: U=453.5, n<sub>1</sub>=26, n<sub>2</sub>=27, <em>p</em>=0.07).</p>
</blockquote>
<p>Notice how the statistics were reported. Because we are describing the test as a Mann-Whitney <em>U</em>-test, it is conventional to quote the test statistic as ‘U’, rather than ‘W’. If we had decided to present the test as a two-sample Wilcoxon test the test can be summarised…</p>
<blockquote>
<p>The rates of removal of prey biomass were not significantly different between ants foraging in oak and in sycamore (two-sample Wilcoxon test: <em>W</em>=453.5, n<sub>1</sub>=26, n<sub>2</sub>=27, <em>p</em>=0.07).</p>
</blockquote>
<p>…remembering to change the name (‘two-sample Wilcoxon test’) and label (‘W’) used to describe the test statistic. In either case, we also have to provide the sample sizes associated with each tree group so that a reader can judge how powerful the test was.</p>
</div>
</div>
<div id="the-kruskal-wallis-test" class="section level2">
<h2><span class="header-section-number">30.6</span> The Kruskal-Wallis test</h2>
<p>The Kruskal-Wallis is the non-parametric equivalent to one-way ANOVA. The Kruskal-Wallis test allows us to test for differences among more than two samples. Like the other rank-based tests we have encountered it has some assumptions, but these are less restrictive than those for ANOVA. The assumptions are essentially the same as those for the Mann-Whitney <em>U</em>-test:</p>
<ul>
<li><p>The variable being tested is measured on ordinal, interval, or ratio scales</p></li>
<li><p>The observations from both groups are independent of one another.</p></li>
<li><p>The distribution of the variable in each group is similar (apart than the fact that they have a different central tendency)</p></li>
</ul>
<p>The third assumption is important, particularly with respect to the skewness of the distributions. The test is at least reasonably robust to differences in the dispersion, but the Kruskal-Wallis test should not be used if the skewness of the variable is different among groups is very different. The reason for this is—just as with Mann-Whitney <em>U</em>-test—that a significant result is hard to interpret.</p>
<p>When all three of the above assumptions are satisfied the Kruskal-Wallis is used as a way of looking for differences in the central tendency of two or more groups groups. A one-way ANOVA evaluates the statistical significance of differences between means of these groups. The null hypothesis of the Kruskal-Wallis test (if all three of the above assumptions) is that the groups <em>have the same median</em>. A significant <em>p</em> value therefore indicates that the medians are likely to be different.</p>
<div id="learning-in-cuttlefish" class="section level3">
<h3><span class="header-section-number">30.6.1</span> Learning in cuttlefish</h3>
<p>In a study of the ability of cuttlefish to learn, an experiment was conducted to determine how the length of exposure to a situation influenced the learning process. Cuttlefish feed on prawns. If they are presented with prawns in a glass tube they strike at them but, obviously, fail to capture the prey. Not surprisingly, after a period of this fruitless activity, they give up striking at the prawns.</p>
<p>In the experiment, 50 cuttlefish were divided at random into 5 groups of 10 and cuttlefish from each group were presented with prawns in glass tubes for different lengths of time: 2 min., 4 min., 8 min., 15 min., and 30 min. for the 5 groups respectively. After 24 hours the same cuttlefish were presented with prawns again and the number of strikes they made (over a fixed period) were recorded.</p>
<p>The data are in the file CUTTLEFISH.CSV. There are two variables: <code>Strikes</code> contains the number of strikes recorded and <code>Time</code> identifies the groups (period of previous exposure):</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="non-parametric-tests.html#cb292-1"></a>cuttlefish &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="dt">file=</span><span class="st">&quot;CUTTLEFISH.CSV&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="non-parametric-tests.html#cb293-1"></a><span class="kw">glimpse</span>(cuttlefish)</span></code></pre></div>
<pre><code>## Rows: 50
## Columns: 2
## $ Strikes &lt;int&gt; 5, 12, 11, 4, 1, 6, 8, 3, 0, 5, 0, 13, 0, 3, 0, 7, 3, 4, 6,...
## $ Time    &lt;chr&gt; &quot;t02&quot;, &quot;t02&quot;, &quot;t02&quot;, &quot;t02&quot;, &quot;t02&quot;, &quot;t02&quot;, &quot;t02&quot;, &quot;t02&quot;, &quot;t0...</code></pre>
<p>Take need to understand the data. Dot plots for each treatment will work here:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="non-parametric-tests.html#cb295-1"></a><span class="kw">ggplot</span>(cuttlefish, <span class="kw">aes</span>(<span class="dt">x =</span> Strikes)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb295-2"><a href="non-parametric-tests.html#cb295-2"></a><span class="st">  </span><span class="kw">geom_dotplot</span>(<span class="dt">binwidth =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>Time)</span></code></pre></div>
<p><img src="stats-for-bio_files/figure-html/cuttlefish-strikes-1.png" width="672" style="display: block; margin: auto;" />
The data are clearly very variable. The combination of the apparent skew and the fact that the data are generally small whole numbers with several equal values in each sample, means that we may not be very successful in using a transformation to beat the data into shape. Let’s use the Kruskal-Wallis test instead.</p>
<p>Predictably, the R function to carry out a Kruskal-Wallis test is called <code>kruskal.test</code>, and it is used in exactly the same way as every other statistical modelling function we have looked at:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="non-parametric-tests.html#cb296-1"></a><span class="kw">kruskal.test</span>(Strikes <span class="op">~</span><span class="st"> </span>Time, <span class="dt">data =</span> cuttlefish)</span></code></pre></div>
<pre><code>## 
## 	Kruskal-Wallis rank sum test
## 
## data:  Strikes by Time
## Kruskal-Wallis chi-squared = 11.042, df = 4, p-value = 0.0261</code></pre>
<p>And… one more time… the elements of the output should be easy to work out. These are a statement of the test used and the data, followed by the results: a test statistic (another type of <span class="math inline">\(\chi^2\)</span> statistic), a degrees of freedom, and the all-important <em>p</em>-value.</p>
<p>We report all of these when writing up results of a Kruskal-Wallis test. However, there is some disagreement in the literature how to report a Kruskal-Wallis test—some people report the statistic as a <span class="math inline">\(\chi^2\)</span>, while others refer to it as an ‘H’ statistic. We will follow the common convention of reporting it as an ‘H’ value.</p>
<p>The test (as with ANOVA) tells us that there is at least one difference among the groups, but it doesn’t tell where the difference or differences are. The output does not give the medians so we cannot judge how the samples are ordered. We can use <code>dplyr</code> to calculate the group-specific medians though:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="non-parametric-tests.html#cb298-1"></a>cuttlefish <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb298-2"><a href="non-parametric-tests.html#cb298-2"></a><span class="st">  </span><span class="kw">group_by</span>(Time) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb298-3"><a href="non-parametric-tests.html#cb298-3"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">Median =</span> <span class="kw">median</span>(Strikes))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 5 x 2
##   Time  Median
##   &lt;chr&gt;  &lt;dbl&gt;
## 1 t02      5  
## 2 t04      3.5
## 3 t08      2.5
## 4 t15      2.5
## 5 t30      0</code></pre>
<p>In this case it is fairly clear that longer periods of exposure to the protected prawn do seem to result in fewer strikes in the later trial. Once we understand what is driving the significant result we’re in a position to write a summary:</p>
<blockquote>
<p>The frequency with which the cuttlefish attacked the prawns was significantly affected by the length of time for which they had been exposed to protected prawns 24h earlier (Kruskal-Wallis test: H=11.04, d.f.=4, p&lt;0.05), with longer prior exposure resulting in lower attack rates.</p>
</blockquote>
<p>If it was important to know exactly which treatments were significantly different, then some sort of multiple comparison test would be useful. There are no non-parametric multiple comparison tests available in base R, but they are implemented in the package called <strong>nparcomp</strong>.</p>
</div>
</div>
<div id="spearmans-rank-correlation" class="section level2">
<h2><span class="header-section-number">30.7</span> Spearman’s rank correlation</h2>
<p>Spearman’s rank correlation (<span class="math inline">\(\rho\)</span>) tests for an association between two numeric variables. It is equivalent to Pearson’s correlation. The advantages of using Spearman’s rank correlation are: 1) the two variables do not need to be normally distributed, and 2) ordinal data can be used. This means Spearman’s rank correlation can be used with data having skewed (or other odd) distributions, or with data originally collected on a rank/ordinal scale.</p>
<p>The key assumptions of Spearman’s rank correlation are:</p>
<ul>
<li><p>Both variables are measured on ordinal, interval or ratio scales.</p></li>
<li><p>There is a monotonic relationship between the two variables.</p></li>
</ul>
<p>A monotonic relationship occurs when, in general, the variables increase in value together, or when the values of one variable increase, the other variable tends to decrease. What this means in practice is that we should not use Spearman’s rank correlation if a scatter plot of the data forms a clear ‘hill’ or ‘valley’ shape.</p>
<p>Spearman’s rank correlation is somewhat less powerful (roughly 91% in some evaluations) than Pearson’s method when the data are suitable for the latter. Otherwise it may even be more powerful. We’ll work through an example to learn about Spearman’s correlation…</p>
<div id="grouse-lekking" class="section level3">
<h3><span class="header-section-number">30.7.1</span> Grouse lekking</h3>
<p>Some bird species, at a particular point in the spring, form ‘leks’—gatherings of birds, with males each defending a small area of ground, displaying, and each mating with such females as he is successful in attracting. In general, in leks, a few birds secure many matings and most birds secure rather few. In a study of lekking in black grouse, a biologist is interested in whether birds that secure many matings in one season also do better the next year. Using a population with many colour-ringed birds he is able to get data for a reasonable number of males from two leks in successive years.</p>
<p>The data are in the file GROUSE.CSV. Read these data into a data frame, calling it <code>grouse</code>.</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="non-parametric-tests.html#cb301-1"></a>grouse &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;GROUSE.CSV&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="non-parametric-tests.html#cb302-1"></a><span class="kw">glimpse</span>(grouse)</span></code></pre></div>
<pre><code>## Rows: 20
## Columns: 2
## $ Year1 &lt;int&gt; 3, 15, 4, 3, 4, 9, 1, 0, 2, 7, 3, 2, 6, 0, 1, 12, 2, 1, 5, 10
## $ Year2 &lt;int&gt; 6, 8, 0, 0, 2, 10, 5, 4, 1, 4, 3, 7, 6, 2, 5, 17, 0, 0, 6, 7</code></pre>
<p>Each row of the data is the number of matings for a male in the two successive leks: <code>Year1</code> (year 1) and <code>Year2</code> (year 2). The first thing we should do is summarise the distribution of each variable:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="non-parametric-tests.html#cb304-1"></a><span class="kw">ggplot</span>(grouse, <span class="kw">aes</span>(<span class="dt">x =</span> Year1)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_dotplot</span>(<span class="dt">binwidth =</span> <span class="dv">2</span>)</span>
<span id="cb304-2"><a href="non-parametric-tests.html#cb304-2"></a><span class="kw">ggplot</span>(grouse, <span class="kw">aes</span>(<span class="dt">x =</span> Year2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_dotplot</span>(<span class="dt">binwidth =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="stats-for-bio_files/figure-html/grouse-years-dist-1.png" width="40%" /><img src="stats-for-bio_files/figure-html/grouse-years-dist-2.png" width="40%" /></p>
<p>Notice that the data are integer-valued (i.e. they are counts). These distributions seems to tie in with the biological observation that the distribution of matings is right-skewed: in both years there are only a few males that have high mating success, with most males securing only a handful of matings. Next we need to visualise the association:</p>
<p><img src="stats-for-bio_files/figure-html/grouse-years-scatter-1.png" width="336" style="display: block; margin: auto;" /></p>
<p>The data are integers, which means there is a risk of over-plotting (points will lie on top of one another). We made the points semi-transparent <code>alpha = 0.5</code> to pick this up where it occurs. It seems clear that mating success is positively associated, but we should confirm this with a statistical test. We’ll base this on Spearman’s correlation.</p>
<p><strong>How do we know to use a correlation analysis with these data?</strong> Although there seems to be an association between the counts, it is not obvious that success in one year ‘causes’ success in another year and neither variable is controlled by the investigator. We’re also not interested in using the success measure in year 1 to predict success in year 2. This indicates that correlation analysis is the appropriate method to evaluate the significance of the association.</p>
<p><strong>Why are we using Spearman’s correlation?</strong> The relationship appears roughly linear, so in that regard Pearson’s correlation might be appropriate. However, the distribution of each count variable is right-skewed, which means the normality assumption is probably suspect in this instance. We’re left with no choice but to use Spearman’s correlation.</p>
<p>Carrying out a correlation analysis using Spearman’s rank correlation in R is simple. Again, we use the <code>cor.test</code> function to do this:</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="non-parametric-tests.html#cb305-1"></a><span class="kw">cor.test</span>(<span class="op">~</span><span class="st"> </span>Year1 <span class="op">+</span><span class="st"> </span>Year2, <span class="dt">method =</span> <span class="st">&quot;spearman&quot;</span>, <span class="dt">data =</span> grouse)</span></code></pre></div>
<pre><code>## Warning in cor.test.default(x = c(3L, 15L, 4L, 3L, 4L, 9L, 1L, 0L, 2L, 7L, :
## Cannot compute exact p-value with ties</code></pre>
<pre><code>## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  Year1 and Year2
## S = 592.12, p-value = 0.01112
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.5547952</code></pre>
<p>The only other thing we had to change, compared to the Pearson’s correlation example, was to set <code>method = "spearman"</code> to specify the use of Spearman’s rank correlation. Notice the warning message: ‘Cannot compute exact p-value with ties’. This is generally not something we need to worry about for this particular test.</p>
<p>The output is very similar to that produced by <code>cor.test</code> when using Pearson’s correlation. Once again, the <code>S = 592.12, p-value = 0.01112</code> line is the one we care about. The main difference is that instead of a <em>t</em>-statistic, we end up working with a different kind of test statistic (‘<em>S</em>’). We aren’t going to explain where this comes from because it’s quite technical. Next we see the <em>p</em>-value. This is generated under the null hypothesis of zero correlation (<span class="math inline">\(\rho = 0\)</span>). Since <em>p</em> &lt; 0.05, we conclude that there is a statistically significant correlation between mating success in successive years. Wait, where are the degrees of freedom? Simple—there aren’t any for a Spearman’s correlation test.</p>
<p>What is the correlation between mating success? That’s given at the bottom of the test output again: <span class="math inline">\(+0.55\)</span>. This says that there is a moderate, positive association between mating success in successive years, which is what we expect from the scatter plot.</p>
<p>When using the Spearman method it is fine to report just the value of the correlation coefficient, the sample size, and the <em>p</em>-value (there is no need to report the test statistic). Here’s how to report the results of this analysis:</p>
<blockquote>
<p>There is a positive association between the number of matings achieved by a particular male in one lek and the number the same male achieves in a subsequent lek (Spearman’s rho=0.55, n=20, p &lt; 0.05).</p>
</blockquote>
</div>
</div>
<div id="why-when" class="section level2">
<h2><span class="header-section-number">30.8</span> Why use non-parametric tests … and when?</h2>
<div id="what-are-the-advantages" class="section level3">
<h3><span class="header-section-number">30.8.1</span> What are the advantages?</h3>
<p>Since most non-parametric tests make relatively weak assumptions about the distribution of the data, they are obviously useful techniques for many situations where the data we have are not well suited to parametric tests. If in doubt, a non-parametric test may be a safe bet. Importantly, since non-parametric tests work with ranks of the original data, they can be used to analyse data originally collected in ordinal, or rank, form.</p>
<p>This is extremely useful in many investigations where the data cannot be collected any other way for example…</p>
<ul>
<li><p>Subjects in a psychology experiment might be asked to rank a series of photographs of people in order of attractiveness</p></li>
<li><p>A panel of tasters judging the sweetness of wines may be able to score sweetness on a rank scale</p></li>
<li><p>Encounters between animals might be scored on the basis of the aggressive behaviours shown which can be put in rank order (retreats, stands ground passively, fights when attacked, initiates attack)</p></li>
<li><p>The apparatus for making actual measurements might be unavailable—but relative comparisons can be made by direct observation, perhaps in the field—e.g. ‘greenness’ of leaves, turbidity of water, crawling speed of caterpillars, order of dung fly species arrival on a new dung pat, etc.</p></li>
</ul>
</div>
<div id="what-are-the-disadvantages" class="section level3">
<h3><span class="header-section-number">30.8.2</span> What are the disadvantages?</h3>
<p>Given their advantages, there has to be a catch otherwise everyone would use non-parametric tests all the time. In fact, they are usually used as a last resort.</p>
<p>One problem with non-parametric tests is that if the data are actually appropriate for a parametric test the equivalent non-parametric test will be less powerful (i.e. less likely to find a difference even if there really is one). For some tests the difference is not enormous—for example, if data are suitable for a <em>t</em>-test the Mann-Whitney <em>U</em>-test is about 95% as powerful as the <em>t</em>-test. For this reason, an appropriate transformation followed by a parametric test will yield a more powerful analysis.</p>
<p>A second limitation of non-parametric tests is that by their very nature, they are less informative than parametric tests. For example, if we find a significant differences between group medians using a Kruskal-Wallis test, it can be difficult to understand which differences are driving the significant effect (methods are available, but they are not easy to use). On the other hand, if we can determine a suitable transformation and use an ANOVA model we can deploy tools such as multiple comparison tests to better understand the data.</p>
<p>Parametric models make stronger distributional assumptions about the data, but in some ways they are much more flexible than non-parametric tests, i.e. there are non-parametric equivalents to some parametric tests, but there are many parametric tests for which there is no readily available non-parametric equivalent (e.g., the more complex designs of ANOVA). There is a non-parametric equivalent to ANOVA for complete randomized block design with one treatment factor, called <em>Friedman’s test</em> (available via the <code>friedman.test</code> function in R), but beyond that the options are very limited unless we are able to use advanced techniques such as the bootstrap.</p>
</div>
<div id="parting-words" class="section level3">
<h3><span class="header-section-number">30.8.3</span> Parting words</h3>
<p>Inappropriately distributed data can result in incorrectly high or low <em>p</em>-values. We should choose the statistical model we use on the basis of what the data look like in relation to the assumptions of the model, and reasons in principle, even if not clearly evident in a small sample, why the population from which the data are drawn might be expected to violate the test assumptions. On the principle that biological data rarely, if ever fully comply with the assumptions of parametric tests, it is sometimes advocated that non-parametric tests should always be used. This is not very good advice. There is more to statistics than just calculating <em>p</em>-values, and where possible, we prefer readily intepretable models to more ‘black box’ approaches. Use both approaches as appropriate and be aware of the strengths and weaknesses of each.</p>

</div>
</div>
</div>



</div>
<div class="footnotes">
<hr />
<ol start="33">
<li id="fn33"><p>There is an alternative to the Wilcoxon test which doesn’t make an assumption about the distribution being symmetrical—called the sign test. This can be done in R, but there isn’t a dedicated function for the sign test, and in any case, it is not very powerful with smaller sample sizes.<a href="non-parametric-tests.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>There are two different ways to use the <code>wilcox.test</code> function for a paired design. These are analogous to the two methods used to carry out a paired sample <em>t</em>-test: the first uses the raw data and makes use of the R’s formula system. The second supplies the function with a vector of differences<a href="non-parametric-tests.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>Of course, if we really were interested in the difference between sycamore, oak <em>and</em> rowan we should use a different test.<a href="non-parametric-tests.html#fnref35" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="contingency-tables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="choosing-models-and-tests.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/davan690/stats-for-bio/edit/master/8_04_non_parametric_tests.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"split_by": "section"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
